# Hi there üëã

I'm **Ania** ‚Äì a recent master's graduate in Digital Economy and an aspiring **Data Analyst**.  
Currently learning and improving my skills in data analytics and visualization. üöÄ  

---

## üîé About Me
- üéì Fresh graduate passionate about turning data into insights  
- üìñ A book lover ‚Äì check out [my Goodreads profile](https://www.goodreads.com/user/show/38242245)  
- üèÉ I enjoy staying active: running & gym training  

---

## üõ†Ô∏è Skills & Tools (learning and practicing)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-003B57?style=for-the-badge&logo=sqlite&logoColor=white)
![Excel](https://img.shields.io/badge/Excel-217346?style=for-the-badge&logo=microsoft-excel&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black)
![MS Office](https://img.shields.io/badge/MS--Office-D83B01?style=for-the-badge&logo=microsoft-office&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![MS Office](https://img.shields.io/badge/Microsoft%20Office-D83B01?style=for-the-badge&logo=microsoft-office&logoColor=white)
![PowerPoint](https://img.shields.io/badge/PowerPoint-B7472A?style=for-the-badge&logo=microsoft-powerpoint&logoColor=white)
![Word](https://img.shields.io/badge/Word-2B579A?style=for-the-badge&logo=microsoft-word&logoColor=white)
![Visual Studio Code](https://img.shields.io/badge/VS%20Code-007ACC?style=for-the-badge&logo=visualstudiocode&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)
![Ubuntu Terminal](https://img.shields.io/badge/Terminal-241F1F?style=for-the-badge&logo=ubuntu&logoColor=E95420)
![Canva](https://img.shields.io/badge/Canva-00C4CC?style=for-the-badge&logo=canva&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=matplotlib&logoColor=white)
![Trello](https://img.shields.io/badge/Trello-0052CC?style=for-the-badge&logo=trello&logoColor=white)
![Google Colab](https://img.shields.io/badge/Google%20Colab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white)
![Google Analytics](https://img.shields.io/badge/Google%20Analytics-E37400?style=for-the-badge&logo=googleanalytics&logoColor=white)
![Power Query](https://img.shields.io/badge/Power%20Query-FFD580?style=for-the-badge&logo=powerbi&logoColor=black)

‚ú® Always eager to learn new tools and improve my analytical mindset!  

Mine projects:

- [Project 1: Book analysis from the Goodreads platform](https://github.com/AnnMane/goodreads_project-)
- [Project 2: Global Streaming Catalog Analysis](https://github.com/AnnMane/GLOBAL_STREAMING_CATALOG_ANALYSIS) 
- [Project 3: Customer Shopping Data Analysis & Automation](https://github.com/AnnMane/customers-shopping) 
---

## [Project 1: Book analysis from the Goodreads platform](https://github.com/AnnMane/goodreads_project-) ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![SQL](https://img.shields.io/badge/SQL-003B57?style=for-the-badge&logo=sqlite&logoColor=white) ![Visual Studio Code](https://img.shields.io/badge/VS%20Code-007ACC?style=for-the-badge&logo=visualstudiocode&logoColor=white)

In this project, I analyzed the relationship between textual book reviews and numeric ratings, using a dataset of books and their reviews. The workflow included the following steps:
- **Data import and cleaning:** Loaded datasets (CSV files) and performed preprocessing, such as splitting publication dates, handling missing values, and standardizing text formats.
- **Exploratory analysis:** Explored the relationship between the number of pages and ratings, as well as other book attributes like publication year or number of reviews.
- **Visualization:** Created several visualizations (PNG files) to present key findings, including the top 10 authors by number of pages, publication year distribution, and summary diagrams comparing review texts and ratings.
- **Script automation:** Wrote and used Python scripts for data cleaning, analysis, and visualization (e.g., mapping variables, generating charts, splitting columns, extracting insights from textual reviews).
- **Documentation:** Summarized requirements and findings in text files, as well as maintained a clear README file describing the project structure and conclusions.
  
**The goal was to uncover patterns between textual reviews and scores, highlight influential authors and books, and practice advanced Python data analysis and visualization techniques. This project demonstrates skills in data cleaning, exploratory data analysis, and informative reporting for book-related datasets.**

## [Project 2: Global Streaming Catalog Analysis](https://github.com/AnnMane/GLOBAL_STREAMING_CATALOG_ANALYSIS) ![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black) ![Power Query](https://img.shields.io/badge/Power%20Query-FFD580?style=for-the-badge&logo=powerbi&logoColor=black) ![DAX](https://img.shields.io/badge/DAX-007ACC?style=for-the-badge&logo=microsoftsqlserver&logoColor=white)

In this project, I created an interactive BI dashboard to analyze and compare the content libraries of three major streaming giants: Netflix, Amazon Prime, and Disney+. The workflow included the following steps:
- **ETL & Data Cleaning**: Ingested and consolidated raw data from three separate sources into a unified model using Power Query. Performed extensive cleaning, including handling missing values, trimming text, and standardizing date formats.
- **Advanced Data Modeling**: Solved a critical "ID Collision" data engineering challenge where different platforms used identical ID schemas. Engineered a Composite Primary Key to ensure 100% accuracy in distinct count calculations across the merged dataset.
- **DAX Calculations**: Developed dynamic measures to calculate unique titles, categorize content into Movies/TV Shows, and analyze historical growth trends.
- **Interactive Visualization**: Designed a professional, dark-themed dashboard featuring custom navigation buttons, drill-through capabilities for detailed data views, and geospatial mapping of content production.
- **Strategic Analysis**: Visualized the "Streaming Wars" by comparing library sizes, the explosion of original content production over the last decade, and the content strategy differences between platforms (e.g., volume vs. curated franchises).

**The goal was to merge disparate datasets into a unified analytical model, solving complex data integration challenges to visualize global content strategies. This project demonstrates proficiency in Power BI, end-to-end ETL processes, and solving real-world data engineering problems like composite key creation.**

## [Project 3: Customer Shopping Data Analysis & Automation](https://github.com/AnnMane/customers-shopping) ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white) ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![SQL](https://img.shields.io/badge/SQL-4479A1?style=for-the-badge&logo=postgresql&logoColor=white)

In this project, I built an end-to-end data analysis pipeline for retail sales data, focusing on **SQL automation and database management** using PostgreSQL and Python. The workflow included the following steps:
- **Database Architecture:** Designed and deployed a PostgreSQL database to store raw customer shopping data, moving beyond static flat files to a robust relational environment.
- **Modular SQL Analysis:** Wrote comprehensive SQL scripts structured in a modular fashion (e.g., `1.0_missing_values.sql`, `2.3_monthly_sales_trends.sql`) to perform data quality checks, customer segmentation, and sales trend analysis.
- **Python Automation (ETL):** Developed a Python script (`excels.py`) using the `psycopg2` library to establish a connection with the database, automatically execute the sequence of SQL queries, and export the processed results into Excel reports.
- **Business Intelligence:** Analyzed key metrics such as top-performing shopping malls, age/gender distribution of customers, and category performance to provide actionable retail insights.
- **Tech Stack Integration:** Demonstrated the ability to integrate VS Code, Python, and PostgreSQL into a seamless workflow for reproducible analysis.

**The goal was to simulate a real-world Data Analyst workflow: querying a live database, automating report generation with Python, and structuring SQL code for maintainability. This project highlights skills in Database Management, Python scripting for automation, and advanced SQL querying.**

## [Project 4: IT Job Market Analysis Dashboard (Poland)](https://github.com/AnnMane/Job_Hunter_Analysis) ![Power BI](https://img.shields.io/badge/Power_BI-F2C811?style=for-the-badge&logo=Power%20BI&logoColor=black) ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) ![DAX](https://img.shields.io/badge/DAX-00758F?style=for-the-badge&logo=powerbi&logoColor=white) ![Ubuntu](https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white)

In this project, I developed an end-to-end data pipeline and interactive dashboard to analyze the Polish IT job market, transforming unstructured web data into actionable career insights. The workflow included the following steps:
- **Data Acquisition & Engineering:** Engineered a custom web scraper using Python to extract over 2,400 active job offers, parsing complex nested structures like salary ranges and tech stacks from the "No Fluff Jobs" portal.
- **Advanced Data Modeling:** Designed a Star Schema with a specialized **Bridge Table** to resolve Many-to-Many relationships between Job Offers and Skills. This architecture allowed for accurate filtering and prevented data duplication errors common in multi-value dimension analysis.
- **ETL & Transformation:** Utilized Power Query (M) to normalize mixed currency data (converting EUR/USD to PLN), handle null values, and parse location strings to distinguish between fully remote work and physical tech hubs.
- **Complex DAX Calculations:** Implemented advanced measures using `DISTINCTCOUNT` and context transition logic to calculate accurate average salaries and "Requirements per Offer," effectively handling data granularity issues.
- **Hybrid Workflow:** Executed the project using a professional hybrid environment, combining Power BI on Windows for visualization with **WSL 2 (Ubuntu)** for Python scripting and Git version control.

**The goal was to provide a transparent view of the IT market, identifying "Hidden Gem" technologies with high salaries but lower competition. This project demonstrates full-stack data analysis skills, from raw data scraping in Linux to advanced dimensional modeling and storytelling in Power BI.**

## Author
¬©2025 Anna Grzywa. All rights reserved.

[<img src="https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white&style=for-the-badge" alt="LinkedIn badge"/>](https://www.linkedin.com/in/annagrzywa/)
